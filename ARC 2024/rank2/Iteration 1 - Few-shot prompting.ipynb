{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af2c559-5a8c-4dd1-a274-04bbda312a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    # Model\n",
    "    #model_path = '/kaggle/input/phi-3/transformers/phi-3-mini-128k-instruct/1/Phi-3-mini-128k-instruct'\n",
    "    model_path = '/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1'\n",
    "    #model_path = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'\n",
    "    #model_path = '/kaggle/input/llama-3.1/transformers/8b-instruct/1'\n",
    "    max_model_len = 8192 #61000 for phi-3\n",
    "    # Dataset\n",
    "    dataset_path = r'C:\\Users\\gavin\\OneDrive\\Documents\\ds_files\\kaggle_arc\\data\\2024\\arc-agi_training_challenges.json'\n",
    "    #dataset_path = '/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json'\n",
    "    #dataset_path = '/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json'\n",
    "    n_tasks = None # Optional parameter to limit the number of task in the inference, set it to None to use all the tasks\n",
    "    # Few-shot\n",
    "    few_shot_dataset_path = r'C:\\Users\\gavin\\OneDrive\\Documents\\ds_files\\kaggle_arc\\data\\2024\\arc-agi_training_challenges.json'\n",
    "    n_shots = 0\n",
    "    # Inference params\n",
    "    max_predictions_per_task = 2 # \n",
    "    sampling_params = dict(temperature=0.0, max_tokens=2000) # https://docs.vllm.ai/en/latest/dev/sampling_params.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09b86aea-4d97-4b25-9c5c-23892824f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_dry_run = cfg.dataset_path == '/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json' and not os.getenv('KAGGLE_IS_COMPETITION_RERUN')\n",
    "# if is_dry_run:\n",
    "#     print('This is a dry run, no inference nor installation of packages will be done')\n",
    "is_dry_run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e5d5f7-be7a-4311-9aea-bdd319934b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# if not is_dry_run:\n",
    "#     try:\n",
    "#         import vllm\n",
    "#     except ImportError:\n",
    "#         !pip uninstall -q -y torch\n",
    "#         !pip install -q --no-index --find-links=/kaggle/input/making-wheels-of-necessary-packages-for-vllm vllm\n",
    "#     # model imports\n",
    "#     from vllm import LLM, SamplingParams\n",
    "#     from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f7bc62b4-d801-4578-b4ce-92619ffae227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import json\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "# from itertools import islice, product\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d73ce879-3382-4c84-85f9-b72f33c8be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridEncoder(ABC):\n",
    "    @abstractmethod\n",
    "    def to_text(self, grid):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def to_grid(self, text):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "145b2033-3dad-45ef-b9cf-0d36a83ff107",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_grid = np.eye(3, dtype=int).tolist()\n",
    "\n",
    "def test_translator(translator):\n",
    "    assert sample_grid == translator.to_grid(translator.to_text(sample_grid))\n",
    "    print(translator.to_text(sample_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d2a565d-f16d-4a3e-8352-35a55cd0b20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "010\n",
      "001\n"
     ]
    }
   ],
   "source": [
    "class MinimalGridEncoder(GridEncoder):\n",
    "    @staticmethod\n",
    "    def to_text(grid):\n",
    "        text = '\\n'.join([''.join([str(x) for x in line]) for line in grid])\n",
    "        return text\n",
    "    \n",
    "    @staticmethod\n",
    "    def to_grid(text):\n",
    "        lines = text.strip().splitlines()\n",
    "        grid = [[int(x) for x in line] for line in lines]\n",
    "        return grid\n",
    "        \n",
    "test_translator(MinimalGridEncoder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5faba10c-be11-4150-8820-260e827e5005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1|0|0\n",
      "0|1|0\n",
      "0|0|1\n"
     ]
    }
   ],
   "source": [
    "class GridWithSeparationEncoder(GridEncoder):\n",
    "    def __init__(self, split_symbol):\n",
    "        self.split_symbol = split_symbol\n",
    "\n",
    "    def to_text(self, grid):\n",
    "        text = '\\n'.join([self.split_symbol.join([str(x) for x in line]) for line in grid])\n",
    "        return text\n",
    "    \n",
    "    def to_grid(self, text):\n",
    "        lines = text.strip().splitlines()\n",
    "        grid = [[int(x) for x in line.split(self.split_symbol)] for line in lines]\n",
    "        return grid\n",
    "        \n",
    "test_translator(GridWithSeparationEncoder('|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c67387dc-29e4-4b38-8eab-2ae0d307c582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```grid\n",
      "100\n",
      "010\n",
      "001\n",
      "```\n",
      "```grid\n",
      "1|0|0\n",
      "0|1|0\n",
      "0|0|1\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "class GridCodeBlockEncoder(GridEncoder):\n",
    "    def __init__(self, base_encoder):\n",
    "        self.encoder = base_encoder\n",
    "    \n",
    "    def to_text(self, grid):\n",
    "        text = f'```grid\\n{self.encoder.to_text(grid)}\\n```'\n",
    "        return text\n",
    "    \n",
    "    def to_grid(self, text):\n",
    "        grid_text = text.split('```grid\\n')[1].split('\\n```')[0]\n",
    "        grid = self.encoder.to_grid(grid_text)\n",
    "        return grid\n",
    "        \n",
    "test_translator(GridCodeBlockEncoder(MinimalGridEncoder()))\n",
    "\n",
    "test_translator(GridCodeBlockEncoder(GridWithSeparationEncoder('|')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5df0fd0f-3da8-4ead-af65-a2a50e813bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptCreator(ABC):\n",
    "    def __init__(self, grid_encoder: GridEncoder):\n",
    "        self.grid_encoder = grid_encoder\n",
    "    \n",
    "    @abstractmethod\n",
    "    def create_task_prompts(self, task):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def parse_response(self, text):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "708ccbb8-15c0-41fd-aa97-ba3142975709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePromptCreator(PromptCreator):\n",
    "\n",
    "    def create_task_prompts(self, task):\n",
    "        if cfg.model_path == '/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1':\n",
    "            # Mistral does not have system prompt\n",
    "            messages = []\n",
    "        else:\n",
    "            messages = [ \n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful AI assistant. Your task is to answer to the user using always the same transformation of the user input.\"}, \n",
    "            ] \n",
    "        for sample in task['train']:\n",
    "            messages.append({\"role\": \"user\", \"content\": f\"Input:\\n{self.grid_encoder.to_text(sample['input'])}\"})\n",
    "            messages.append({\"role\": \"assistant\", \"content\": f\"Output:\\n{self.grid_encoder.to_text(sample['output'])}\"})\n",
    "\n",
    "        prompts = []\n",
    "        for test_sample in task['test']:\n",
    "            final_message = {\"role\": \"user\", \"content\": f\"Input:\\n{self.grid_encoder.to_text(test_sample['input'])}\"}\n",
    "            prompt = tokenizer.apply_chat_template(messages + [final_message],\n",
    "                                                   tokenize=False,\n",
    "                                                   add_generation_prompt=True)\n",
    "            prompts.append(prompt)\n",
    "        return prompts\n",
    "    \n",
    "    def parse_response(self, text):\n",
    "        grid_text = text.split('Output:\\n')[1]\n",
    "        return self.grid_encoder.to_grid(grid_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0893ae8-d6ed-49fd-8d17-d107b13a59f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "puzzle_explanations = {\n",
    "    '00576224': \"\"\"The pattern of the input is repeated to generate the output.\n",
    "\n",
    "1. The first two rows are obtained by simply repeating the 2x2 pattern 3 times along the cols axis.\n",
    "2. The following two rows are obtained by flipping the pattern horizontally and repeating it 3 times\n",
    "3. The final two rows are identical to the first ones, simply repeat the 2x2 pattern 3 times.\n",
    "\n",
    "Thus the output is 3 times bigger than the input (6x6 vs 2x2) because the pattern is repeated 3 times in the row and col axis.\"\"\",\n",
    "    '009d5c81': \"\"\"To create the output we have to copy the input with two modifications:\n",
    "\n",
    "1. The object with color 1 is removed and replaced with the background color 0\n",
    "2. The color of the other object (there are only two objects in the grid) is modified.\n",
    "  The new color of this object depends on the shape of the object of color 1. There is a mapping\n",
    "  between shapes and colors. Just look at the train examples for an object of the same shape\n",
    "  and see the color that is applied on the output.\"\"\",\n",
    "    '00dbd492': \"\"\"The input shows a square with color 2 that is empty except from a point in the center.\n",
    "The output is created by colorizing the inside of the square. The color is chosen depending on the size of the squares.\n",
    "The larger square is painted with 3, the medium with 4 and the small with 8.\"\"\",\n",
    "    '03560426': \"\"\"The input shows objects of different colors at the bottom of the grid.\n",
    "The output is created by moving the objects to the top left corner. The objects are moved from left to right order.\n",
    "The first object is placed at the top left corner, the second object is placed at the lower right corner of the first object,\n",
    "the third object is placed at the lower right corner of the second object and so on. There is oclusion between the objects,\n",
    "in those oclusions we see the rightmost object.\"\"\",\n",
    "    '0607ce86': \"\"\"This is a denoising task. The input shows the same object repeated many times, but there are noisy pixels in the grid.\n",
    "The output is created by removing all the noise in the grid. The background should be completely 0.\n",
    "The real object without noise can be guessed because there are many repetitions of the object, so we simply have to\n",
    "look at the majority pixel on each location.\"\"\",\n",
    "    '0692e18c': \"\"\"The ouptut is created following this steps.\n",
    "\n",
    "1. The input is upscaled x3. So if the input is 3x3 the output should be an upscaled version of the input 9x9\n",
    "2. We apply an AND function in a sliding window fashion over the output using the inverted input pattern (take the input and swicth the background color 0 with the other color and viceversa)\n",
    "    \"\"\",\n",
    "    '070dd51e': \"\"\"The output is created by simply drawing horizontal and vertical lines between cells with the same color.\n",
    "If there is an intersection between lines the vertical line will be shown.\"\"\",\n",
    "    '08573cc6': \"\"\"The output is created by drawing an spiral that starts at the cell with color 1.\n",
    "The colors of the spiral are taken from the first two cells of the grid, which will be removed in the output.\"\"\",\n",
    "    '0a2355a6': \"\"\"The output is created by copying the input and changing the color of the objects.\n",
    "The new color will be chosen depending on the number of holes of the object. There is a mapping between number of holes and color that can be observed from the input examples.\"\"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2010a58e-3f0c-4348-818d-27d432b5f237",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewShotPromptCreator(PromptCreator):\n",
    "    task_description = \"\"\"You are a helpful AI assistant. Your job is to solve tasks from the Abstraction and Reasoning Challenge (ARC). \n",
    "The user will present you with sample input and output grids for each task. \n",
    "Your job will be to understand the transformation between the input and the output and apply it to the last input grid given by the user. \n",
    "The puzzle-like inputs and outputs present a grid where each square can be one of ten colors. A grid can be any height or width between 1x1 and 30x30.\n",
    "The background of the grid is typically colored with 0.\n",
    "The tasks from ARC are based on the following priors:\n",
    "\n",
    "- Objectness: Objects persist and cannot appear or disappear without reason. Objects can interact or not depending on the circumstances.\n",
    "- Goal-directed: Objects can be animate or inanimate. Some objects are \"agents\" - they have intentions and they pursue goals.\n",
    "- Numbers & counting: Objects can be counted or sorted by their shape, appearance, or movement using basic mathematics like addition, subtraction, and comparison.\n",
    "- Basic geometry & topology: Objects can be shapes like rectangles, triangles, and circles which can be mirrored, rotated, translated, deformed, combined, repeated, etc. Differences in distances can be detected.\n",
    "\n",
    "The transformations between input and output should be based on these priors.\n",
    "\"\"\"\n",
    "    def __init__(self, grid_encoder):\n",
    "        super().__init__(grid_encoder)\n",
    "        with open(cfg.few_shot_dataset_path, 'r') as f:\n",
    "            self.few_shot_tasks = json.load(f)\n",
    "        with open(cfg.few_shot_dataset_path.replace('challenges.json', 'solutions.json'), 'r') as f:\n",
    "            self.few_shot_solutions = json.load(f)\n",
    "        self.few_shot_tasks = {task_id: self.few_shot_tasks[task_id] for task_id in puzzle_explanations}\n",
    "        self.few_shot_solutions = {task_id: self.few_shot_solutions[task_id] for task_id in puzzle_explanations}\n",
    "        self.few_shot_task_ids = list(self.few_shot_tasks.keys())\n",
    "        self.n_shots = cfg.n_shots\n",
    "    \n",
    "    def create_task_prompts(self, task):\n",
    "        messages = [{\"role\": \"system\", \"content\": self.task_description}]\n",
    "        \n",
    "        for task_id in np.random.choice(self.few_shot_task_ids, self.n_shots):\n",
    "            few_shot_task = self.few_shot_tasks[task_id]\n",
    "            user_message = self.create_user_message_for_train_examples(few_shot_task)\n",
    "            for test_idx, test_sample in enumerate(few_shot_task['test']):\n",
    "                user_message += self.create_input_message('Test case', test_sample)\n",
    "                messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "                user_message = ''\n",
    "                assistant_message = f'{puzzle_explanations[task_id]}\\n\\n' + self.create_output_message(self.few_shot_solutions[task_id][test_idx])\n",
    "                messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "\n",
    "        user_message = self.create_user_message_for_train_examples(task)        \n",
    "        prompts = []\n",
    "        for test_sample in task['test']:\n",
    "            user_message += self.create_input_message('Test case', test_sample)\n",
    "            messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "            prompt = tokenizer.apply_chat_template(messages,\n",
    "                                                   tokenize=False,\n",
    "                                                   add_generation_prompt=True)\n",
    "            prompts.append(prompt)\n",
    "        return prompts\n",
    "    \n",
    "    def create_user_message_for_train_examples(self, task):\n",
    "        user_message = \"Let's see if you can solve this simple ARC task. These are some input-output grid examples that define the task.\\n\"\n",
    "        for example_idx, sample in enumerate(task['train']):\n",
    "            user_message += self.create_input_message(f'Example {example_idx}', sample)\n",
    "            user_message += '\\n' + self.create_output_message(sample['output'])\n",
    "        return user_message\n",
    "\n",
    "    def create_input_message(self, title, sample):\n",
    "        return f\"\\n## {title}\\n\\n### Input\\n\\n{self.grid_encoder.to_text(sample['input'])}\\n\"\n",
    "    \n",
    "    def create_output_message(self, grid):\n",
    "        return f\"### Output\\n\\n{self.grid_encoder.to_text(grid)}\\n\"\n",
    "    \n",
    "    def parse_response(self, text):\n",
    "        return self.grid_encoder.to_grid(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "487a4cbc-f5d1-4f2c-98b8-1acc06fa4de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sample_prompt(data, prompt_creator):\n",
    "    prompts = [prompt_creator.create_task_prompts(task)[0] for task in data.values()]\n",
    "    prompts = sorted(prompts, key=lambda x: len(x))\n",
    "    pretty_print_prompt(prompts[0])\n",
    "    \n",
    "def pretty_print_prompt(text):\n",
    "    color = 'black'\n",
    "    attrs = None\n",
    "    for line in text.splitlines():\n",
    "        if line.startswith('<|assistant|>'):\n",
    "            color = 'blue'\n",
    "        elif line.startswith('<|user|>'):\n",
    "            color = 'black'\n",
    "        elif line.startswith('<|system|>'):\n",
    "            color = 'green'\n",
    "            \n",
    "        if line.startswith('<'):\n",
    "            attrs = ['bold']\n",
    "        else:\n",
    "            attrs = None\n",
    "        print(colored(line, color, attrs=attrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82609677-0525-46c1-97c1-f5dd5bd240dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_input_token_length_distribution(data, prompt_creator):\n",
    "    prompts = []\n",
    "    for task in data.values():\n",
    "        prompts.extend(prompt_creator.create_task_prompts(task))\n",
    "    token_length_distribution = [len(tokenizer.tokenize(prompt)) for prompt in tqdm(prompts)]\n",
    "    plt.title('Prompt token length distribution')\n",
    "    plt.hist(token_length_distribution)\n",
    "    plt.xlabel('n tokens')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (v3.11)",
   "language": "python",
   "name": "py3_11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
